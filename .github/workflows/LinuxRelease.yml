name: LinuxRelease
on: [push, pull_request,repository_dispatch]
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-${{ github.head_ref || '' }}-${{ github.base_ref || '' }}-${{ github.ref != 'refs/heads/master' || github.sha }}
  cancel-in-progress: true

jobs:
  linux-extensions-64:
    name: Linux Extensions (x64)
    runs-on: ubuntu-latest
    container: ubuntu:16.04
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.S3_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_KEY }}
      AWS_DEFAULT_REGION: us-east-1

    steps:
    # Todo we now do a lot of this shit twice, because we cannot get submodule without a recent git
    - name: Install stuff
      shell: bash
      run: |
        apt-get update -y -qq
        apt-get install -y -qq software-properties-common
        add-apt-repository ppa:git-core/ppa
        apt-get update -y -qq
        apt-get install -y -qq ninja-build make gcc-multilib g++-multilib libssl-dev wget openjdk-8-jdk zip maven unixodbc-dev libc6-dev-i386 lib32readline6-dev libssl-dev libcurl4-gnutls-dev libexpat1-dev gettext unzip build-essential checkinstall libffi-dev curl libz-dev openssh-client

    - name: Install Git 2.18.5
      shell: bash
      run: |
        wget https://github.com/git/git/archive/refs/tags/v2.18.5.tar.gz
        tar xvf v2.18.5.tar.gz
        cd git-2.18.5
        make
        make prefix=/usr install
        git --version

    - uses: actions/checkout@v3
      with:
        fetch-depth: 0
        submodules: 'true'

    - uses: ./duckdb/.github/actions/ubuntu_16_setup

    # Build extension
    - name: Build extension
      shell: bash
      env:
        GEN: ninja
      run: |
        make release

      # TODO: when adding S3 uploads, this can do remote tests
    - name: Test
      shell: bash
      run: |
        ./duckdb/scripts/extension-upload-test.sh local oote

    - uses: actions/upload-artifact@v2
      with:
        name: linux-extensions-64
        path: |
          build/release/duckdb/extension/*/*.duckdb_extension

#    # Deploy binary # todo_replace bogus version when we have confirmed this will not bork production
#    - name: Deploy
#      shell: bash
#      run: |
#        ./scripts/extension-upload.sh bogus_platform bogus_version ${{ secrets.S3_BUCKET }} 0

  manylinux-extensions:
    name: Linux Extensions (x64, GCC4)
    runs-on: ubuntu-latest
    container: quay.io/pypa/manylinux2014_x86_64
    env:
      GEN: ninja

    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0
        submodules: 'true'

    # TODO: move CENTOS7 setup to action, use ninja in main duckdb
    - name: Install dependencies
      shell: bash
      run: |
        yum install -y gcc gcc-c++ cmake make
        yum install -y epel-release
        yum install -y make gcc perl-core pcre-devel wget zlib-devel python3
        yum install -y https://packages.endpointdev.com/rhel/7/os/x86_64/endpoint-repo.x86_64.rpm
        yum install -y git
        yum install -y curl-devel expat-devel gettext-devel zlib-devel perl-ExtUtils-MakeMaker
        yum install -y ninja-build

    - name: Install AWS CLI
      shell: bash
      run: |
        python3 -m pip install awscli
        aws --version

    # Build extension
    - name: Build extension
      shell: bash
      run: |
        make release

      # TODO: when adding S3 uploads, this can do remote tests
    - name: Test
      shell: bash
      run: |
        ./duckdb/scripts/extension-upload-test.sh local oote

    - uses: actions/upload-artifact@v2
      with:
        name: manylinux-extensions-x86_64
        path: |
          build/release/duckdb/extension/*/*.duckdb_extension

#    # Deploy binary # todo_replace bogus version when we have confirmed this will not bork production
#    - name: Deploy
#      shell: bash
#      run: |
#        ./duckdb/scripts/extension-upload.sh bogus_platform bogus_version ${{ secrets.S3_BUCKET }} 0

  linux-extensions-64-aarch64:
    name: Linux Extensions (aarch64)
    runs-on: ubuntu-latest
    container: ubuntu:18.04 # cross compiler not available in 16
    env:
      GEN: ninja

    steps:
      - name: Install stuff
        shell: bash
        run: |
          apt-get update -y -qq
          apt-get install -y -qq software-properties-common
          add-apt-repository ppa:git-core/ppa
          apt-get update -y -qq
          apt-get install -y -qq ninja-build make gcc-multilib g++-multilib libssl-dev wget openjdk-8-jdk zip maven unixodbc-dev libc6-dev-i386 lib32readline6-dev libssl-dev libcurl4-gnutls-dev libexpat1-dev gettext unzip build-essential checkinstall libffi-dev curl libz-dev openssh-client

      - name: Install Git 2.18.5
        shell: bash
        run: |
          wget https://github.com/git/git/archive/refs/tags/v2.18.5.tar.gz
          tar xvf v2.18.5.tar.gz
          cd git-2.18.5
          make
          make prefix=/usr install
          git --version

      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
          submodules: 'true'

      - uses: ./duckdb/.github/actions/ubuntu_16_setup
        with:
          aarch64_cross_compile: 1

      # Build extension
      - name: Build extension
        shell: bash
        run: |
          make release

      # TODO: when adding S3 uploads, this can do remote tests

      # This doesnt work, the script cannot handle the fact that we build from a different cmake root
      - name: Test
        shell: bash
        run: |
          ./duckdb/scripts/extension-upload-test.sh local oote

      - uses: actions/upload-artifact@v2
        with:
          name: linux-extensions-64-aarch64
          path: |
            build/release/duckdb/extension/*/*.duckdb_extension